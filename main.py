import argparse
import os
import sys
from dotenv import load_dotenv
from pydub import AudioSegment
from transformers import pipeline

# â”€â”€â”€ ffmpeg ãƒ‘ã‚¹è¨­å®šï¼ˆOSåˆ¥ï¼‰
def get_ffmpeg_path() -> str:
    base = os.path.join(os.path.dirname(__file__), 'ffmpeg')
    if sys.platform.startswith('win'):
        return os.path.join(base, 'windows', 'ffmpeg.exe')
    elif sys.platform == 'darwin':
        return os.path.join(base, 'mac', 'ffmpeg')
    else:
        return os.path.join(base, 'linux', 'ffmpeg')

# â”€â”€â”€ ffmpeg ã‚’ PATH ã«è¿½åŠ 
FFMPEG_BINARY = get_ffmpeg_path()
if os.path.exists(FFMPEG_BINARY):
    path_dir = os.path.dirname(FFMPEG_BINARY)
    os.environ['PATH'] = os.pathsep.join([path_dir, os.environ.get('PATH', '')])
    if sys.platform.startswith('win'):
        os.environ['FFMPEG_BINARY'] = FFMPEG_BINARY

# â”€â”€â”€ .env ã‹ã‚‰ãƒˆãƒ¼ã‚¯ãƒ³ã‚’èª­ã¿è¾¼ã‚€ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³æ‰±ã„ï¼‰
load_dotenv()
HF_TOKEN = os.getenv("HF_TOKEN")  # ä»Šå¾Œã¯ä¸è¦ã«ãªã‚‹ãŒãƒ­ã‚°ã‚¤ãƒ³æ¸ˆãƒã‚§ãƒƒã‚¯ç”¨ã«ä¿æŒ

def transcribe(path: str, model: str, use_gpu: bool = False):
    device = 0 if use_gpu else -1

    # å…¥åŠ›éŸ³å£°ã‚’ä¸€æ™‚ WAV ã«å¤‰æ›
    audio = AudioSegment.from_file(path)
    temp_path = "temp_audio.wav"
    audio.export(temp_path, format="wav")

    # Whisper ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ã¯æ—¢ã«èªè¨¼æ¸ˆã¿ãªã®ã§æ¸¡ã•ãªã„ï¼‰
    asr = pipeline(
        "automatic-speech-recognition",
        model=model,
        device=device
    )

    result = asr(temp_path)
    os.remove(temp_path)

    return result["text"]

def main(argv=None):
    parser = argparse.ArgumentParser(description='Simple CLI for speech recognition')
    parser.add_argument('file', help='audio file path')
    parser.add_argument('--model', default='openai/whisper-small', help='HuggingFace model name')
    parser.add_argument('--use-gpu', action='store_true', help='Enable GPU acceleration')
    args = parser.parse_args(argv)

    print("ğŸ” ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­ï¼ˆã“ã‚Œã¯åˆå›ã¯æ™‚é–“ã‹ã‹ã‚‹ã‚ˆï¼‰â€¦")
    text = transcribe(args.file, args.model, args.use_gpu)
    
    print("\nâœ… --- èªè­˜çµæœ --- âœ…\n")
    print(text)

if __name__ == '__main__':
    main()
